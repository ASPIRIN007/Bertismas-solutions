{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":"<p>Welcome \u2014 this site contains my worked solutions.</p> <ul> <li>Chapter 1</li> <li>Chapter 2</li> </ul>"},{"location":"chapter1/","title":"Chapter 1","text":""},{"location":"chapter1/#notes","title":"Notes","text":"<ul> <li>Notes</li> </ul>"},{"location":"chapter1/#exercises","title":"Exercises","text":"<ul> <li>Exercise 1.1*</li> </ul>"},{"location":"chapter1/ex1-1/","title":"Exercise 1.1*","text":"<p>Suppose \\(f:\\mathbb{R}^n \\to \\mathbb{R}\\) is both concave and convex. Prove \\(f\\) is affine.</p>"},{"location":"chapter1/ex1-1/#solution","title":"Solution","text":"<p>Since \\(f\\) is convex and concave, for any \\(x,y\\) and \\(0\\le \\lambda \\le 1\\), [ f(\\lambda x + (1-\\lambda)y)=\\lambda f(x)+(1-\\lambda)f(y). ]</p> <p>Define \\(g(x)=f(x)-f(0)\\). Then \\(g(0)=0\\) and the equality implies linearity (additivity + homogeneity), so \\(g(x)=a^T x\\) and \\(f(x)=f(0)+a^T x\\), i.e. affine.</p>"},{"location":"chapter1/notes/","title":"Notes","text":"<p>Key box</p> <p>These notes are typed from my handwritten Chapter 1 notes and capture the main definitions + reformulations:</p> <ol> <li>General LP formulation (objective + constraint families)  </li> <li>Turning equalities into inequalities and writing LP in matrix form  </li> <li>Local vs global minima; convexity fact  </li> <li>Piecewise-linear convex objectives and epigraph reformulation  </li> <li>Absolute value modeling (two equivalent LP reformulations)  </li> <li>Graphical (2D) geometry + solution method  </li> <li>Subspaces, span, and affine subspaces  </li> </ol>"},{"location":"chapter1/notes/#introduction-general-lp-form","title":"Introduction: General LP Form","text":"<p>In a general linear programming (LP) problem, we are given a cost vector \\(c=(c_1,\\dots,c_n)\\) and we seek to minimize a linear function \\(c^\\mathsf{T}x=\\sum_{i=1}^n c_i x_i\\) over a decision vector \\(x=(x_1,\\dots,x_n)\\), subject to linear equality/inequality constraints.</p> <p>Let \\(M_1,M_2,M_3\\) be finite index sets. For each constraint \\(i\\), we are given: - an \\(n\\)-dimensional vector \\(a_i\\), - a scalar \\(b_i\\),</p> <p>and these form the \\(i\\)-th linear constraint.</p> <p>Let \\(N_1,N_2 \\subseteq \\{1,\\dots,n\\}\\) indicate which variables are constrained to be nonnegative or nonpositive, respectively.</p> <p>Def box \u2014 General LP</p> <p>\\(\\begin{aligned} \\min\\ &amp; c^\\mathsf{T}x\\\\[2mm] \\text{s.t. }  &amp; a_i^\\mathsf{T}x \\ge b_i, &amp;&amp; i\\in M_1,\\\\ &amp; a_i^\\mathsf{T}x \\le b_i, &amp;&amp; i\\in M_2,\\\\ &amp; a_i^\\mathsf{T}x = b_i, &amp;&amp; i\\in M_3,\\\\ &amp; x_j \\ge 0, &amp;&amp; j\\in N_1,\\\\ &amp; x_j \\le 0, &amp;&amp; j\\in N_2. \\end{aligned}\\)</p> <p>Terminology</p> <ul> <li>Variables \\(x_1,\\dots,x_n\\) are decision variables.  </li> <li>A vector \\(x\\) satisfying all constraints is a feasible solution (feasible vector).  </li> <li>The set of all feasible solutions is the feasible set / feasible region.  </li> <li>If \\(j\\notin N_1\\cup N_2\\), then \\(x_j\\) is a free (unrestricted) variable.  </li> <li>The function \\(c^\\mathsf{T}x\\) is the objective function / cost function.  </li> <li>A feasible solution minimizing the objective is an optimal solution \\(x^\\star\\).  </li> <li>The value \\(c^\\mathsf{T}x^\\star\\) is the optimal cost.</li> </ul>"},{"location":"chapter1/notes/#converting-constraints-matrix-form","title":"Converting Constraints + Matrix Form","text":""},{"location":"chapter1/notes/#equality-as-two-inequalities","title":"Equality as two inequalities","text":"<p>Equality constraint equivalence</p> <p>An equality constraint can be written as two inequalities: \\(a_i^\\mathsf{T}x=b_i \\quad \\Longleftrightarrow \\quad  \\big(a_i^\\mathsf{T}x\\le b_i\\big)\\ \\text{and}\\ \\big(a_i^\\mathsf{T}x\\ge b_i\\big).\\)</p> <p>Also, constraints like \\(x_j\\ge 0\\) or \\(x_j\\le 0\\) can be viewed as special cases of linear inequalities.</p>"},{"location":"chapter1/notes/#expressing-everything-as-one-inequality-direction","title":"Expressing everything as one inequality direction","text":"<p>By multiplying some constraints by \\(-1\\), we can express the feasible set using inequalities of a single direction (e.g. all \u201c\\(\\ge\\)\u201d constraints).</p> <p>Def box \u2014 Matrix form (one-direction inequalities)</p> <p>We can write an LP in matrix form as \\(\\begin{aligned} \\min\\ &amp; c^\\mathsf{T}x\\\\ \\text{s.t. } &amp; Ax \\ge b, \\end{aligned}\\) where \\(A\\) is formed by stacking appropriate row vectors (derived from the \\(a_i^\\mathsf{T}\\)), \\(x=[x_1,\\dots,x_n]^\\mathsf{T}\\), and \\(b=[b_1,\\dots,b_m]^\\mathsf{T}\\).</p>"},{"location":"chapter1/notes/#local-vs-global-minima-convexity-fact","title":"Local vs Global Minima (Convexity Fact)","text":"<p>Def box \u2014 Local minimum</p> <p>A vector \\(x\\) is a local minimum of \\(f\\) if \\(f(x)\\le f(y)\\) for all \\(y\\) in a neighborhood of \\(x\\).</p> <p>Def box \u2014 Global minimum</p> <p>A vector \\(x\\) is a global minimum of \\(f\\) if \\(f(x)\\le f(y)\\) for all \\(y\\).</p> <p>Key fact (convexity)</p> <p>A convex function cannot have a local minimum that is not a global minimum.</p>"},{"location":"chapter1/notes/#piecewise-linear-convex-functions","title":"Piecewise-Linear Convex Functions","text":"<p>Let \\(c_1,\\dots,c_m\\in\\mathbb{R}^n\\) be vectors and \\(d_1,\\dots,d_m\\in\\mathbb{R}\\) be scalars. Consider \\(f(x)=\\max_{i=1,\\dots,m}\\big(c_i^\\mathsf{T}x+d_i\\big).\\)</p> <p>Key box</p> <p>The function \\(f(x)=\\max_i (c_i^\\mathsf{T}x+d_i)\\) is convex and is called a piecewise-linear convex function.</p> <p>Piecewise-linear convex functions can be used to approximate more general convex functions.</p>"},{"location":"chapter1/notes/#lp-with-piecewise-linear-convex-objective-epigraph-trick","title":"LP with piecewise-linear convex objective (epigraph trick)","text":"<p>Consider the problem: \\(\\min\\ \\max_{i=1,\\dots,m}(c_i^\\mathsf{T}x+d_i) \\quad \\text{s.t.}\\quad Ax\\ge b.\\)</p> <p>Introduce \\(z\\) as the smallest number satisfying \\(z\\ge c_i^\\mathsf{T}x+d_i\\) for all \\(i\\). Then we can reformulate as an LP:</p> <p>Epigraph reformulation</p> <p>\\(\\begin{aligned} \\min\\ &amp; z\\\\ \\text{s.t. } &amp; z \\ge c_i^\\mathsf{T}x+d_i,\\quad i=1,\\dots,m,\\\\ &amp; Ax\\ge b. \\end{aligned}\\)</p>"},{"location":"chapter1/notes/#constraint-of-the-form-fxle-h","title":"Constraint of the form \\(f(x)\\le h\\)","text":"<p>If \\(f\\) is piecewise-linear convex, \\(f(x)=\\max_{i=1,\\dots,m}(f_i^\\mathsf{T}x+g_i),\\) then a constraint \\(f(x)\\le h\\) can be written as the system: \\(f_i^\\mathsf{T}x+g_i\\le h,\\quad i=1,\\dots,m.\\)</p>"},{"location":"chapter1/notes/#problems-involving-absolute-values","title":"Problems Involving Absolute Values","text":"<p>Consider: \\(\\min \\sum_{i=1}^n c_i|x_i| \\quad \\text{s.t.}\\quad Ax\\ge b.\\)</p>"},{"location":"chapter1/notes/#lp-formulation-a-introduce-z_i-absolute-value-linearization","title":"LP formulation A: introduce \\(z_i\\) (absolute value linearization)","text":"<p>Absolute value via \\(z_i\\)</p> <p>Introduce \\(z_i\\ge 0\\) such that \\(z_i\\ge |x_i|\\) using: \\(x_i \\le z_i,\\qquad -x_i \\le z_i,\\qquad i=1,\\dots,n.\\) Then the LP becomes: \\(\\begin{aligned} \\min\\ &amp; \\sum_{i=1}^n c_i z_i\\\\ \\text{s.t. } &amp; Ax\\ge b,\\\\ &amp; x_i \\le z_i,\\ \\ -x_i \\le z_i,\\quad i=1,\\dots,n. \\end{aligned}\\)</p>"},{"location":"chapter1/notes/#lp-formulation-b-split-variables-xx-x-","title":"LP formulation B: split variables \\(x=x^+-x^-\\)","text":"<p>Write each \\(x_i\\) as difference of two nonnegative variables: \\(x_i=x_i^+-x_i^-\\) with \\(x_i^+,x_i^-\\ge 0\\). Then \\(|x_i|=x_i^++x_i^-\\).</p> <p>Absolute value via split variables</p> <p>Replace: \\(x = x^+ - x^-,\\) and \\(|x_i| = x_i^+ + x_i^-.\\) Then: \\(\\begin{aligned} \\min\\ &amp; \\sum_{i=1}^n c_i(x_i^+ + x_i^-)\\\\ \\text{s.t. } &amp; A x^+ - A x^- \\ge b,\\\\ &amp; x^+\\ge 0,\\ \\ x^-\\ge 0. \\end{aligned}\\)</p>"},{"location":"chapter1/notes/#graphical-representation-and-solution-2d","title":"Graphical Representation and Solution (2D)","text":""},{"location":"chapter1/notes/#core-geometry","title":"Core geometry","text":"<p>Let the feasible set be \\(P=\\{x\\mid Ax\\le b\\}.\\)</p> <p>Key box \u2014 Core geometry</p> <ul> <li>\\(P\\) is a polyhedron (intersection of half-spaces).  </li> <li>In 2D, \\(P\\) is a polygonal region (possibly unbounded).  </li> <li>Each inequality \\(a_i^\\mathsf{T}x\\le b_i\\) defines a half-plane.  </li> <li>The boundary \\(a_i^\\mathsf{T}x=b_i\\) is a line.</li> </ul> <p>Def box \u2014 Corner/vertex</p> <p>A corner / vertex is a point in \\(P\\) that cannot be written as a nontrivial convex combination of other feasible points.</p> <p>Def box \u2014 Edge/face</p> <p>An edge/face is the set of feasible points where some constraints hold with equality.</p>"},{"location":"chapter1/notes/#objective-geometry-and-the-graphical-method-2d","title":"Objective geometry and the graphical method (2D)","text":"<p>Consider objective level sets: \\(c^\\mathsf{T}x=\\alpha.\\)</p> <p>Graphical method (2D)</p> <ol> <li>Plot each constraint boundary line and choose the correct feasible half-plane.  </li> <li>Find the intersection polygon (the feasible region).  </li> <li>Slide the objective line \\(c^\\mathsf{T}x=\\alpha\\) outward (in the improving direction) until the last point of contact with the feasible region.  </li> <li>That last contact point (or contact edge) gives the optimum.</li> </ol>"},{"location":"chapter1/notes/#subspaces-and-span","title":"Subspaces and Span","text":"<p>Def box \u2014 Subspace</p> <p>A nonempty subset \\(S\\subseteq \\mathbb{R}^n\\) is a subspace of \\(\\mathbb{R}^n\\) if for every \\(x,y\\in S\\) and every \\(a,b\\in\\mathbb{R}\\), \\(ax+by\\in S.\\) If \\(S\\ne \\mathbb{R}^n\\), then \\(S\\) is a proper subspace.</p> <p>Key property</p> <p>Every subspace contains the zero vector.</p> <p>Def box \u2014 Span</p> <p>The span of vectors \\(y^1,\\dots,y^K\\in\\mathbb{R}^n\\) is the set \\(\\mathrm{span}\\{y^1,\\dots,y^K\\}   =\\left\\{\\sum_{k=1}^K a_k y^k \\;:\\; a_k\\in\\mathbb{R}\\right\\}.\\)</p>"},{"location":"chapter1/notes/#affine-subspaces","title":"Affine Subspaces","text":"<p>Let \\(S_0\\) be a subspace of \\(\\mathbb{R}^n\\) and let \\(x^0\\in\\mathbb{R}^n\\). Define: \\(S = S_0 + x^0 = \\{s + x^0 \\mid s\\in S_0\\}.\\)</p> <p>Def box \u2014 Affine subspace</p> <p>In general, \\(S\\) is not a subspace because it may not contain the zero vector. Such a translated set \\(S=S_0+x^0\\) is called an affine subspace.</p>"},{"location":"chapter2/","title":"Chapter 2","text":""},{"location":"chapter2/#notes","title":"Notes","text":"<ul> <li>Notes</li> </ul>"},{"location":"chapter2/notes2/","title":"Notes","text":""},{"location":"chapter2/notes2/#21-polyhedra-and-convex-sets","title":"2.1 Polyhedra and Convex Sets","text":"<p>Key box</p> <p>Section 2.1 sets up the geometry language used throughout LP:</p> <ol> <li>A polyhedron is the feasible set of finitely many linear inequalities  </li> <li>Bounded vs unbounded sets (can the feasible region extend to infinity?)  </li> <li>Hyperplanes (equalities) and halfspaces (inequalities)  </li> <li>Convexity: the line segment between feasible points stays feasible  </li> <li>Convex combinations and the convex hull </li> <li>Closure facts (Theorem 2.1): intersections preserve convexity; polyhedra are convex  </li> </ol>"},{"location":"chapter2/notes2/#polyhedra-feasible-sets-of-lp-constraints","title":"Polyhedra (feasible sets of LP constraints)","text":"<p>Def box \u2014 Polyhedron</p> <p>A polyhedron is any set that can be written as \\(P=\\{x\\in\\mathbb{R}^n \\mid Ax \\ge b\\},\\) i.e., the set of vectors satisfying finitely many linear inequalities.</p> <p>Interpretation: each inequality is a \u201ccut\u201d of the space; the feasible region is what remains after applying all cuts.</p>"},{"location":"chapter2/notes2/#boundedness","title":"Boundedness","text":"<p>Def box \u2014 Bounded set</p> <p>A set \\(S\\subseteq\\mathbb{R}^n\\) is bounded if there exists a constant \\(K\\) such that \\(|x_i|\\le K\\) for every \\(x\\in S\\) and each component \\(i\\).</p> <ul> <li>Bounded polyhedron: trapped inside some big box.  </li> <li>Unbounded polyhedron: you can move infinitely far in some direction while staying feasible.</li> </ul> <p>Why it matters later: unboundedness can lead to LPs with no finite optimum (depending on the objective direction).</p>"},{"location":"chapter2/notes2/#hyperplanes-and-halfspaces-single-linear-constraints","title":"Hyperplanes and Halfspaces (single linear constraints)","text":"<p>Let \\(a\\neq 0\\) and \\(b\\in\\mathbb{R}\\).</p> <p>Def box \u2014 Hyperplane</p> <p>The hyperplane with normal \\(a\\) and offset \\(b\\) is \\(H=\\{x\\in\\mathbb{R}^n \\mid a^\\mathsf{T}x=b\\}.\\)</p> <p>Def box \u2014 Halfspace</p> <p>The halfspace defined by the inequality is \\(S=\\{x\\in\\mathbb{R}^n \\mid a^\\mathsf{T}x\\ge b\\}.\\)</p> <p>Key geometric facts - The hyperplane \\(a^\\mathsf{T}x=b\\) is the boundary of the halfspace \\(a^\\mathsf{T}x\\ge b\\). - The vector \\(a\\) is perpendicular (normal) to the hyperplane:</p> <p>If \\(x,y\\in H\\), then \\(a^\\mathsf{T}x=b\\) and \\(a^\\mathsf{T}y=b\\), so   \\(a^\\mathsf{T}(x-y)=0,\\)   meaning any direction along the hyperplane is orthogonal to \\(a\\).</p> <p>Polyhedron viewpoint \\(P=\\{x\\mid Ax\\ge b\\}\\) is the intersection of finitely many halfspaces (one per row of \\(A\\)).</p>"},{"location":"chapter2/notes2/#convex-sets-the-main-structural-property","title":"Convex Sets (the main structural property)","text":"<p>Def box \u2014 Convex set</p> <p>A set \\(S\\subseteq\\mathbb{R}^n\\) is convex if for any \\(x,y\\in S\\) and any \\(\\lambda\\in[0,1]\\), \\(\\lambda x + (1-\\lambda)y\\in S.\\) (Equivalently: the whole line segment between any two points in \\(S\\) lies in \\(S\\).)</p> <p>Why convexity matters for LP - If \\(x\\) and \\(y\\) are feasible, then any \u201cmix\u201d of them is feasible. - This property is fundamental for later results like \u201can optimum occurs at a corner/extreme point.\u201d</p>"},{"location":"chapter2/notes2/#convex-combinations-and-convex-hull","title":"Convex combinations and convex hull","text":"<p>Def box \u2014 Convex combination</p> <p>A vector \\(z\\) is a convex combination of \\(x^1,\\dots,x^k\\) if \\(z=\\sum_{i=1}^k \\lambda_i x^i,\\) where \\(\\lambda_i\\ge 0\\) and \\(\\sum_{i=1}^k \\lambda_i = 1.\\)</p> <p>Def box \u2014 Convex hull</p> <p>The convex hull of points \\(x^1,\\dots,x^k\\) is the set of all their convex combinations: \\(\\mathrm{conv}\\{x^1,\\dots,x^k\\} = \\left\\{\\sum_{i=1}^k \\lambda_i x^i \\; \\middle|\\; \\lambda_i\\ge 0,\\ \\sum_{i=1}^k\\lambda_i=1\\right\\}.\\) It is the smallest convex set containing those points.</p>"},{"location":"chapter2/notes2/#theorem-21-closure-properties-youll-use-repeatedly","title":"Theorem 2.1 (closure properties you\u2019ll use repeatedly)","text":"<p>Theorem box \u2014 Basic convexity facts</p> <ol> <li>The intersection of convex sets is convex.  </li> <li>Every polyhedron is convex.    (Halfspaces are convex, and a polyhedron is an intersection of halfspaces.)  </li> <li>If \\(S\\) is convex and \\(x^1,\\dots,x^k\\in S\\), then every convex combination \\(\\sum_{i=1}^k \\lambda_i x^i\\) lies in \\(S\\).  </li> <li>The convex hull of finitely many points is convex.</li> </ol> <p>Proof idea (what to remember)</p> <ul> <li>Halfspace convexity: if \\(a^\\mathsf{T}x\\ge b\\) and \\(a^\\mathsf{T}y\\ge b\\), then \\(a^\\mathsf{T}(\\lambda x+(1-\\lambda)y)   =\\lambda a^\\mathsf{T}x+(1-\\lambda)a^\\mathsf{T}y   \\ge \\lambda b+(1-\\lambda)b=b.\\) </li> <li>Intersections preserve convexity: if the segment stays in each set, it stays in their intersection.</li> </ul> <p>Section 2.1 \u2014 Exam checklist</p> <ul> <li>A feasible set of linear inequalities is a polyhedron: \\(P=\\{x\\mid Ax\\ge b\\}\\).  </li> <li>Each inequality defines a halfspace; equalities define hyperplanes.  </li> <li>Polyhedra are convex (intersection of convex halfspaces).  </li> <li>Bounded means contained in a box; unbounded means it extends to infinity.  </li> <li>Convex combination and convex hull formalize \u201cmixing\u201d feasible points.</li> </ul>"},{"location":"chapter2/notes2/#22-extreme-points-vertices-and-basic-feasible-solutions","title":"2.2 Extreme Points, Vertices, and Basic Feasible Solutions","text":"<p>Key box</p> <p>Section 2.2 formalizes what a \u201ccorner\u201d of a polyhedron means, in three equivalent ways:</p> <ol> <li>Extreme point (purely geometric: cannot be written as a nontrivial convex combination)  </li> <li>Vertex (optimization view: unique optimizer for some linear objective)  </li> <li>Basic feasible solution (BFS) (algebraic test: \\(n\\) linearly independent active constraints)  </li> </ol> <p>Main result: Extreme points = vertices = BFS (Theorem 2.2). It also defines adjacent basic solutions (sets up simplex \u201cmove along an edge\u201d).</p>"},{"location":"chapter2/notes2/#221-extreme-points","title":"2.2.1 Extreme points","text":"<p>Def box \u2014 Extreme point</p> <p>Let \\(P\\) be a convex set (in particular, a polyhedron). A point \\(x\\in P\\) is an extreme point of \\(P\\) if it cannot be expressed as a nontrivial convex combination of two distinct points of \\(P\\).</p> <p>Equivalently: if \\(y,z\\in P\\) and \\(0\\le \\lambda \\le 1\\) satisfy \\(x=\\lambda y+(1-\\lambda)z,\\) then either \\(x=y\\), or \\(x=z\\), or \\(\\lambda\\in\\{0,1\\}\\).</p> <p>Geometric meaning: extreme points are the true \u201ccorners\u201d \u2014 you cannot obtain them by \u201cmixing\u201d two other feasible points.</p>"},{"location":"chapter2/notes2/#222-vertices-supporting-hyperplane-lp-viewpoint","title":"2.2.2 Vertices (supporting-hyperplane / LP viewpoint)","text":"<p>Def box \u2014 Vertex</p> <p>Let \\(P\\) be a polyhedron. A point \\(x\\in P\\) is a vertex of \\(P\\) if it is the unique optimal solution of some linear program with feasible set \\(P\\).</p> <p>That is, there exists a vector \\(c\\) such that \\(x\\) is the unique minimizer of \\(\\min\\{c^\\mathsf{T}u \\mid u\\in P\\}.\\)</p> <p>Geometric meaning: there is a supporting hyperplane (a level set of a linear objective) that touches \\(P\\) only at \\(x\\).</p>"},{"location":"chapter2/notes2/#223-active-constraints-and-enough-equalities-to-pin-down-a-point","title":"2.2.3 Active constraints and \u201cenough equalities to pin down a point\u201d","text":"<p>Let the polyhedron be written as \\(P=\\{x\\in\\mathbb{R}^n \\mid a_i^\\mathsf{T}x \\ge b_i,\\ i=1,\\dots,m\\}.\\)</p> <p>At a point \\(x\\in P\\), constraint \\(i\\) is active if it holds with equality: \\(a_i^\\mathsf{T}x=b_i.\\)</p> <p>Terminology \u2014 Active set</p> <p>The active set at \\(x\\) is the index set \\(I(x)=\\{i\\in\\{1,\\dots,m\\} \\mid a_i^\\mathsf{T}x=b_i\\}.\\)</p> <p>Key idea: if the active constraints at \\(x\\) include \\(n\\) linearly independent normals, then those equalities determine \\(x\\) uniquely (they \u201cpin down\u201d the point like a corner).</p>"},{"location":"chapter2/notes2/#224-basic-solutions-and-basic-feasible-solutions","title":"2.2.4 Basic solutions and basic feasible solutions","text":"<p>Def box \u2014 Basic feasible solution (BFS)</p> <p>A feasible point \\(x\\in P\\) is a basic feasible solution if among the active constraints at \\(x\\), there exist \\(n\\) linearly independent constraints.</p> <p>(Equivalently: the active constraint normals span \\(\\mathbb{R}^n\\).)</p> <p>Remark \u2014 Basic solution vs BFS</p> <p>Often one forms a basic solution by selecting \\(n\\) linearly independent constraints, solving them as equalities to obtain a unique candidate \\(x\\), and then checking feasibility.</p> <ul> <li>If the resulting \\(x\\) satisfies all constraints, it is a basic feasible solution.  </li> <li>If it violates some constraints, it is a basic solution but not feasible.</li> </ul> <p>Important remark (representation issue)</p> <p>Whether a point is a basic solution can depend on how the polyhedron is written (which constraints you include, redundant constraints, etc.).</p> <p>However, the main theorem below shows that BFS are the same as extreme points, so the property \u201cbeing a BFS\u201d is ultimately geometric (representation-independent).</p>"},{"location":"chapter2/notes2/#225-main-equivalence-theorem","title":"2.2.5 Main equivalence theorem","text":"<p>Theorem box \u2014 Extreme point = vertex = BFS</p> <p>Let \\(P\\) be a polyhedron. For a point \\(x\\in P\\), the following are equivalent:</p> <ol> <li>\\(x\\) is a vertex of \\(P\\).  </li> <li>\\(x\\) is an extreme point of \\(P\\).  </li> <li>\\(x\\) is a basic feasible solution of \\(P\\).  </li> </ol> <p>Why this theorem matters - It justifies the \u201ccorner\u201d viewpoint in three ways:   - geometry: extreme point,   - optimization: vertex,   - algebra: BFS (what algorithms can test and move between).</p>"},{"location":"chapter2/notes2/#226-finiteness-of-basic-solutions","title":"2.2.6 Finiteness of basic solutions","text":"<p>Key fact \u2014 There are finitely many basic solutions</p> <p>A polyhedron defined by finitely many constraints has only finitely many ways to choose \\(n\\) linearly independent constraints.</p> <p>Therefore, the number of basic solutions (and hence BFS / extreme points) is finite.</p>"},{"location":"chapter2/notes2/#227-adjacency-neighbors-and-edges","title":"2.2.7 Adjacency (neighbors) and edges","text":"<p>Def box \u2014 Adjacent basic solutions</p> <p>Two distinct basic solutions are adjacent if they share \\(n-1\\) linearly independent active constraints.</p> <p>Geometric meaning</p> <p>If two basic feasible solutions are adjacent, the line segment joining them lies on an edge of the polyhedron. (This is the geometric backbone of simplex: move from one BFS to an adjacent BFS along an edge.)</p> <p>Section 2.2 \u2014 Exam checklist</p> <ul> <li>Know the three corner notions:</li> <li>Extreme point = cannot be written as a nontrivial convex combination  </li> <li>Vertex = unique optimizer for some linear objective  </li> <li>BFS = \\(n\\) linearly independent active constraints at the point  </li> <li>Be able to state: Extreme point \u21d4 Vertex \u21d4 BFS.  </li> <li>Know adjacency: share \\(n-1\\) independent active constraints (neighbors along an edge).</li> </ul>"}]}